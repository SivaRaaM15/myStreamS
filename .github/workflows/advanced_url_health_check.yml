name: Advanced URL Health Check

on:
  schedule:
    - cron: '0 */6 * * *'
  push:
    branches: [ main ]
  workflow_dispatch:

jobs:
  advanced-url-check:
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Install dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y curl parallel jq

    - name: Download M3U file from GitHub Raw
      run: |
        M3U_URL="https://raw.githubusercontent.com/SivaRaaM15/myStreamS/refs/heads/main/sivarenu.m3u"
        echo "Fetching M3U from: $M3U_URL"
        curl -fsSL "$M3U_URL" -o sivarenu.m3u || {
          echo "Failed to download M3U file!"
          exit 1
        }
        if [ ! -s "sivarenu.m3u" ]; then
          echo "Downloaded M3U is empty!"
          exit 1
        fi
        echo "M3U file downloaded successfully."

    - name: Advanced URL Health Check
      run: |
        set -euo pipefail

        echo "Starting Advanced URL Health Check..."
        echo "==============================================="

        mkdir -p results
        > report.jsonl
        > summary.log

        # Parse M3U: extract title (tvg-id) and URL
        awk '
          /^#EXTINF/ {
            title = $0
            gsub(/.*tvg-id="/, "", title)
            gsub(/".*/, "", title)
            if (title == "") title = "Unknown"
          }
          /^https?:\/\// {
            print title "|" $0
          }
        ' sivarenu.m3u > url_list.txt

        TOTAL_URLS=$(wc -l < url_list.txt)
        echo "Found $TOTAL_URLS streams to test."

        if [ "$TOTAL_URLS" -eq 0 ]; then
          echo "No URLs found in M3U!"
          exit 1
        fi

        # Test function â€” builds valid JSON with jq
        test_url() {
          local line="$1"
          local num="$2"
          local title=$(echo "$line" | cut -d'|' -f1)
          local url=$(echo "$line" | cut -d'|' -f2- | sed 's/[[:space:]]*$//')

          local result_file="results/result_$num.json"
          local log_file="results/log_$num.txt"

          # Default values
          local http_code="000"
          local content_type="unknown"
          local redirect_count=0
          local total_time=0
          local is_stream=0
          local has_ts=0
          local bitrate="unknown"
          local token_expiry="unknown"
          local status="failed"

          # Clean URL
          local clean_url="$url"

          # HTTP HEAD request
          local response
          response=$(curl -s -I -L --max-time 12 \
            -A "VLC/3.0.0 LibVLC/3.0.0" \
            -H "Accept: application/x-mpegURL, */*" \
            --write-out "\nHTTP_CODE:%{http_code}\nCONTENT_TYPE:%{content_type}\nREDIRECTS:%{num_redirects}\nTIME_TOTAL:%{time_total}" \
            "$clean_url" 2>/dev/null || echo "HTTP_CODE:000")

          http_code=$(echo "$response" | grep -m1 "HTTP_CODE:" | cut -d: -f2)
          content_type=$(echo "$response" | grep -m1 "CONTENT_TYPE:" | cut -d: -f2- | head -1)
          redirect_count=$(echo "$response" | grep -m1 "REDIRECTS:" | cut -d: -f2)
          total_time=$(echo "$response" | grep -m1 "TIME_TOTAL:" | cut -d: -f2)

          # Stream checks only if HTTP 200/206
          if [[ "$http_code" == "200" || "$http_code" == "206" ]]; then
            if echo "$content_type" | grep -qi "mpegurl\|m3u8"; then
              # Check for #EXTM3U
              if curl -s --max-time 8 -r 0-2048 "$clean_url" | grep -q "#EXTM3U"; then
                is_stream=1
              fi

              # Try to get first .ts segment
              local base_url="${clean_url%/*}"
              local ts_line
              ts_line=$(curl -s --max-time 8 "$clean_url" | grep -m1 "\.ts$" || true)
              if [ -n "$ts_line" ] && [[ "$ts_line" != http* ]]; then
                local ts_url="$base_url/$ts_line"
                if curl -s -I --max-time 8 "$ts_url" 2>/dev/null | grep -q "200"; then
                  has_ts=1
                fi
              fi

              # Extract bitrate
              bitrate=$(curl -s --max-time 8 "$clean_url" | grep -m1 "BANDWIDTH" | grep -o "BANDWIDTH=[0-9]*" | cut -d= -f2 || echo "unknown")
              [ "$bitrate" = "" ] && bitrate="unknown"
            fi
          fi

          # Token expiry for ciinema.net
          if echo "$clean_url" | grep -q "ciinema.net.*e=[0-9]*"; then
            local expiry_sec
            expiry_sec=$(echo "$clean_url" | grep -o "e=[0-9]*" | cut -d= -f2)
            local now_sec
            now_sec=$(date +%s)
            local diff_sec=$(( expiry_sec - now_sec ))
            if [ $diff_sec -gt 0 ]; then
              local hours=$(( diff_sec / 3600 ))
              token_expiry="${hours}h"
            else
              token_expiry="expired"
            fi
          fi

          # Determine status
          if [[ "$http_code" == "200" || "$http_code" == "206" ]]; then
            if [ $is_stream -eq 1 ] && [ $has_ts -eq 1 ]; then
              status="healthy"
            elif [ $is_stream -eq 1 ]; then
              status="warning"
            else
              status="caution"
            fi
          fi

          # Build valid JSON with jq
          jq -n \
            --arg idx "$num" \
            --arg t "$title" \
            --arg u "$clean_url" \
            --arg hc "$http_code" \
            --arg ct "$content_type" \
            --arg rc "$redirect_count" \
            --arg tt "$total_time" \
            --argjson stream "$is_stream" \
            --argjson ts "$has_ts" \
            --arg br "$bitrate" \
            --arg te "$token_expiry" \
            --arg st "$status" \
            '{
              index: $idx,
              title: $t,
              url: $u,
              http_code: $hc,
              content_type: $ct,
              redirects: $rc,
              response_time: $tt,
              is_stream: $stream,
              has_ts_segment: $ts,
              bitrate: $br,
              token_expiry: $te,
              status: $st
            }' > "$result_file"

          # Log to summary
          {
            echo "[$num] $title"
            echo "   URL: ${clean_url:0:60}..."
            echo "   HTTP: $http_code | Type: $content_type"
            echo "   Time: ${total_time}s | Redirects: $redirect_count"
            echo "   Stream: $([ $is_stream -eq 1 ] && echo "Yes" || echo "No") | TS: $([ $has_ts -eq 1 ] && echo "Yes" || echo "No")"
            echo "   Status: $status"
            [ "$token_expiry" != "unknown" ] && echo "   Token: $token_expiry"
            echo
          } > "$log_file"
        }

        export -f test_url
        seq 1 $TOTAL_URLS | parallel -j 3 --halt now,fail=1 test_url

        # Combine all JSON results
        for f in results/result_*.json; do cat "$f"; echo; done > report.jsonl

        # Generate summary
        HEALTHY=$(jq 'select(.status == "healthy")' report.jsonl | wc -l)
        WARNING=$(jq 'select(.status == "warning")' report.jsonl | wc -l)
        CAUTION=$(jq 'select(.status == "caution")' report.jsonl | wc -l)
        FAILED=$(jq 'select(.status == "failed")' report.jsonl | wc -l)

        {
          echo "==============================================="
          echo "ADVANCED URL HEALTH CHECK SUMMARY"
          echo "==============================================="
          echo "Generated: $(date -u '+%Y-%m-%d %H:%M:%SZ')"
          echo "Total URLs: $TOTAL_URLS"
          echo "Healthy: $HEALTHY"
          echo "Warning: $WARNING"
          echo "Caution: $CAUTION"
          echo "Failed: $FAILED"
          echo "==============================================="
          echo
          echo "DETAILED LOGS:"
          echo "--------------"
          for f in results/log_*.txt; do cat "$f"; done
        } > health-summary.txt

        echo "Check completed successfully."

        # Exit code logic
        if [ $HEALTHY -eq 0 ]; then
          echo "CRITICAL: No healthy streams found!"
          exit 1
        elif [ $((HEALTHY + WARNING)) -lt $((TOTAL_URLS / 2)) ]; then
          echo "WARNING: Less than 50% operational"
          exit 0
        else
          echo "SUCCESS: System healthy"
          exit 0
        fi

    - name: Upload Health Report
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: url-health-report
        path: |
          sivarenu.m3u
          health-summary.txt
          report.jsonl
          results/
        retention-days: 7
